{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python377jvsc74a57bd000b158a6c28b14537e288aace7cd3af6e299df762960738ddd9b5c3154ab3878",
   "display_name": "Python 3.7.7 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# History and Resources\n",
    "\n",
    "<p>\n",
    "    <img src = \"assets/1.png\">\n",
    "</p>\n",
    "\n",
    "- 1943: If you connect very simple binary neurons, you can do logical operations or reasoning. They had an hypothesis that brain has a very large network (actually a fact) of binary neurons which can turn on/off.\n",
    "- 1947: Donald Hebb, a psychologist came up with the proposal that neurons in the brain can change their function by sort of changing the strength of the connection between the neurons. He proposed that if two neurons are active at the same time then the synapse that connects them strengthens and if they're not active then it gets depressed. This is called **Hebbian Learning**.\n",
    "- 1948: Founded a discipline called cybernetics, now called as system theory or stuff like that; out of that came the idea of self-organization - that if you connect lots of very simple elements with a very simple rule to make them compute, then they might be able to self-organize themselves into having an emergent property.\n",
    "- 1957: **Frank Rosenblatt** introduced the idea of Perceptron, which has now become the basis of Supervised Learning. This idea introduced the concept of weights and how they are updated with the corresponding loss. \n",
    "- 1961, 62: Adaline was introduced, much similar to a basic linear classifier. Around that time, neuroscientists discovered some basic properties about the visual cortex i.e., the neurons in the visual cortex basically look at kind of a small area of the visual field and many neurons at different places of individual cortex basically perform similar operation.\n",
    "- 1969: Marvin Minsky publihsed the limits of perceptrons and asked people to work on something else so the field died; people started working on logical reasoning  and stuff.\n",
    "\n",
    "**The main reasons for the field dying off in 1960 are:**\n",
    "\n",
    "- The researchers used neurons that were binary. However, the way to get backpropagation to work is to use activation functions that are continuous. At that time, researchers didn’t have the idea of using continuous neurons and they didn’t think they can train with gradients because binary neurons are not differential.\n",
    "- With continuous neurons, one would have to multiply the activation of a neuron by a weight to get a contribution to the weighted sum. However, before 1980, the multiplication of two numbers, especially floating-point numbers, were extremely slow. This resulted in another incentive to avoid using continuous neurons.\n",
    "\n",
    "<p>\n",
    "    <img src = \"assets/2.png\">\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "    <img src = \"assets/3.png\">\n",
    "</p>\n",
    "\n",
    "- 1970s: People started working on Statistical Pattern Recognition or basically changed the name of what they were working on\n",
    "- 1979: He came up with the idea of Neocognitron getting inspired by Hubel and Weisel and tried to simulate the visual cortex\n",
    "- 1982: Physicists started getting interested in NN; Hopfield came up with the theory for a type of recurrent neural network that he showed could be used as associative memories.\n",
    "- 1983: Introduced Boltzmann machines; answered the cons of previous models like perceptrons, which were single layer models. But these had multiple layers between them, called the hidden layers.\n",
    "- 1985,86: With backprop, a major conceptual change was introduced to switch from binary neurons to continuous neurons because they were differential.\n",
    "- 1989: Yann LeCun introduced CNN's.\n",
    "- 2003: Yoshua bengio came up with neural language model; GPT-3 uses this idea.\n",
    "\n",
    "<p>\n",
    "    <img src = \"assets/4.png\">\n",
    "</p>\n",
    "\n",
    "Hot Future things to work on acc. to Yann:\n",
    "- Self-supervised Learning\n",
    "- Transformers in CV\n",
    "- Machine reasoning\n",
    "- Autonomous intelligent machines (AGI he mean)\n",
    "\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "\n",
    "<p>\n",
    "    <img src = \"assets/5.png\">\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "    <img src = \"assets/6.png\">\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "    <img src = \"assets/7.png\">\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "    <img src = \"assets/8.png\">\n",
    "</p>\n",
    "\n",
    "### Hierarchical representation of the Visual Cortex\n",
    "\n",
    "Experiments by Fukushima gave us an understanding of how our brain interprets the input to our eyes. In summary, it was discovered that neurons in front of our retina compress the input (known as contrast normalization) and the signal travels from our eyes to our brain. After this, the image gets processed in stages and certain neurons get activated for certain categories. Hence, the visual cortex does pattern recognition in a hierarchical manner.\n",
    "\n",
    "Experiments in which researchers poked electrodes in specific areas of the visual cortex, specifically the V1 area made researchers realize that certain neurons react to motifs that appear in a very small area in a visual field and similarly with neighbouring neurons and neighbouring areas in the visual field. Additionally, neurons that react to the same visual field, react to different types of edges in an organized manner (e.g. vertical or horizontal edges). It is also important to note that there’s also the idea that the visual process is essentially a feed forward process. Hence, somehow fast recognition can be done without some recurrent connections.\n",
    "\n",
    "<p>\n",
    "    <img src = \"assets/9.png\">\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "    <img src = \"assets/10.png\">\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "    <img src = \"assets/11.png\">\n",
    "</p>\n",
    "\n",
    "**Multilayer networks are successful because they exploit the compositional structure of natural data.** In compositional hierarchy, combinations of objects at one layer in the hierarchy form the objects at the next layer. If we mimic this hierarchy as multiple layers and let the network learn the appropriate combination of features, we get what is called Deep Learning architecture. Thus, Deep Learning networks are hierarchical in nature.\n",
    "\n",
    "<p>\n",
    "    <img src = \"assets/12.png\">\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "    <img src = \"assets/13.png\">\n",
    "</p>\n",
    "\n",
    "Feature extraction consists of expanding the representational dimension such that the expanded features are more likely to be linearly separable; data points in higher dimensional space are more likely to be linearly separable due to the increase in the number of possible separating planes.\n",
    "\n",
    "Earlier machine learning practitioners relied on high quality, hand crafted, and task specific features to build artificial intelligence models, but with the advent of Deep Learning, the models are able to extract the generic features automatically. Some common approaches used in feature extraction algorithms are highlighted below:\n",
    "\n",
    "Space tiling\n",
    "Random Projections\n",
    "Polynomial Classifier (feature cross-products)\n",
    "Radial basis functions\n",
    "Kernel Machines\n",
    "Because of the compositional nature of data, learned features have a hierarchy of representations with increasing level of abstractions. For example:\n",
    "\n",
    "Images - At the most granular level, images can be thought of as pixels. Combination of pixels constitute edges which when combined forms textons (multi-edge shapes). Textons form motifs and motifs form parts of the image. By combining these parts together we get the final image.\n",
    "\n",
    "Text - Similarly, there is an inherent hierarchy in textual data. Characters form words, when we combine words together we get word-groups, then clauses, then by combining clauses we get sentences. Sentences finally tell us what story is being conveyed.\n",
    "\n",
    "Speech - In speech, samples compose bands, which compose sounds, which compose phones, then phonemes, then whole words, then sentences, thus showing a clear hierarchy in representation.\n",
    "\n",
    "<p>\n",
    "    <img src = \"assets/14.png\">\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "    <img src = \"assets/15.png\">\n",
    "</p>\n",
    "\n",
    "\n",
    "There are those who dismiss Deep Learning: if we can approximate any function with 2 layers, why have more?\n",
    "\n",
    "For example: SVMs find a separating hyperplane “in the span of the data”, meaning predictions are based on comparisons to training examples. SVMs are essentially a very simplistic 2 layer neural net, where the first layer defines “templates” and the second layer is a linear classifier. The problem with 2 layer fallacy is that the complexity and size of the middle layer is exponential in NN (to do well with a difficult task, need LOTS of templates). But if you expand the number of layers to \\log(N)log(N), the layers become linear in NN. There is a trade-off between time and space.\n",
    "\n",
    "An analogy is designing a circuit to compute a boolean function with no more than two layers of gates – we can compute any boolean function this way! But, the complexity and resources of the first layer (number of gates) quickly becomes infeasible for complex functions.\n",
    "\n",
    "What is “deep”?\n",
    "\n",
    "An SVM isn’t deep because it only has two layers\n",
    "A classification tree isn’t deep because every layer analyses the same (raw) features\n",
    "A deep network has several layers and uses them to build a hierarchy of features of increasing complexity\n",
    "How can models learn representations (good features)?\n",
    "\n",
    "Manifold hypothesis: natural data lives in a low-dimensional manifold. Set of possible images is essentially infinite, set of “natural” images is a tiny subset. For example: for an image of a person, the set of possible images is on the order of magnitude of the number of face muscles they can move (degrees of freedom) ~ 50. An ideal (and unrealistic) feature extractor represents all the factors of variation (each of the muscles, lighting, etc.)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}